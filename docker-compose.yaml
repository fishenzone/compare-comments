services:
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant_db
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./qdrant_data:/qdrant/storage
    restart: always

  vllm:
    image: vllm/vllm-openai:latest
    container_name: vllm_server
    ports:
      - "8000:8000"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    command: [
        "--model", "Qwen/Qwen2.5-7B-Instruct",
        "--max-model-len", "32768",
        "--gpu-memory-utilization", "0.6",
        "--host", "0.0.0.0",
        "--port", "8000"
      ]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: always

  app:
    container_name: rag_app
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
    volumes:
      - ./app:/app/app
      - ./data:/app/data
      - ./uploads:/app/uploads
      - ./results:/app/results
    command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8001", "--reload"]
    depends_on:
      - qdrant
      - vllm
